# üó∫Ô∏è Yandex Maps Scraper - Open Source Edition

**Author**: Daniil Kovekh  
**Project Status**: Educational / Research Prototype  
**License**: MIT (See disclaimer below)

A powerful, user-friendly tool to scrape business data, reviews, and photos from Yandex Maps. Built with Python, Selenium, and Streamlit.

---

## üöÄ Features

-   **Data Extraction**: Scrapes name, address, phone, website, working hours, social media links, and more.
-   **Photos**: Downloads high-quality photos to organized folders.
-   **Reviews**: Extracts recent reviews with ratings and authors.
-   **Multi-Format Export**: Saves data as **CSV**, **JSON**, **SQLite**, and **Excel (.xlsx)**.
-   **User Interface**: Easy-to-use **Streamlit** web dashboard.
-   **Headless Mode**: Runs in the background (server-ready) or visible mode for debugging.

---

## ‚ö†Ô∏è Disclaimer & Legal Notice

**This tool is for EDUCATIONAL and RESEARCH purposes only.**

-   **Not for Commercial Use**: Do not use this tool to scrape data for commercial resale or competitive intelligence without permission.
-   **Terms of Service**: Automated scraping may violate Yandex Maps' Terms of Service. You are solely responsible for compliance with all applicable laws and regulations in your jurisdiction.
-   **Robot Traffic**: This tool uses Selenium to simulate a real user. Excessive use may lead to IP bans. Use responsibly with reasonable limits.

**This is an individual open-source project, not associated with any studio or corporation.**

---

## üõ†Ô∏è Installation

### Prerequisites
-   **Python 3.8+** installed on your system.
-   **Google Chrome** browser installed.

### Setup

1.  **Clone the repository**:
    ```bash
    git clone https://github.com/yourusername/yandex-maps-scraper.git
    cd yandex-maps-scraper
    ```

2.  **Create a virtual environment (Recommended)**:
    ```bash
    python -m venv venv
    # Windows
    venv\Scripts\activate
    # Mac/Linux
    source venv/bin/activate
    ```

3.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

---

## üñ•Ô∏è Usage

You can run the scraper in two ways: using the **GUI (Streamlit)** or the **Command Line**.

### Option 1: Web Interface (Streamlit) - Recommended

The easiest way to use the tool.

```bash
streamlit run streamlit_app.py
```

This will open `http://localhost:8501` in your browser.
-   **Region/City**: Enter the target city (e.g., "Moscow").
-   **Search Query**: Enter the business type (e.g., "Coffee shop").
-   **Max Results**: Limit how many places to scrape.
-   **Headless Mode**:
    -   **Checked (Default)**: Browser runs hidden in the background. Use this for servers or if you don't want to be disturbed.
    -   **Unchecked**: You will see the Chrome window open and navigate automatically. Useful for debugging or seeing what's happening.

### Option 2: Command Line Interface (CLI)

For integration into scripts or quick runs.

```bash
python main.py "Coffee shop Moscow" --max 10
```

**Arguments:**
-   `query`: The search term (e.g., "Coffee shop Moscow").
-   `--max`, `-m`: Maximum number of results (default: 10).
-   `--headless`: Run without visible browser window.
-   `--screenshots`: Capture a screenshot of each place's website (requires Playwright).

---

## üìÇ Output Data

All data is saved in the `output_data` directory, organized by timestamp and query.

Example structure:
```
output_data/
‚îî‚îÄ‚îÄ 20260112_120000_Coffee_shop_Moscow/
    ‚îú‚îÄ‚îÄ places_data.csv       # Spreadsheet for Excel/Analysis
    ‚îú‚îÄ‚îÄ places_data.xlsx      # Excel file
    ‚îú‚îÄ‚îÄ places_data.json      # Full data structure
    ‚îú‚îÄ‚îÄ places_data.db        # SQLite database
    ‚îú‚îÄ‚îÄ 001_Coffee_Mania/     # Folder for specific place
    ‚îÇ   ‚îî‚îÄ‚îÄ photos/           # Downloaded images
    ‚îî‚îÄ‚îÄ ...
```

---

## ü§ñ Advanced: Running on a Server

This tool uses **Selenium** and **Chrome**. To run it on a headless Linux server (e.g., VPS), ensure you have:
1.  Chrome installed (`google-chrome-stable`).
2.  Drivers installed (`chromedriver` is managed automatically by `webdriver-manager`).
3.  Run with **Headless Mode** enabled.

---

## ü§ù Contributing

Contributions are welcome! Please fork the repository and submit a Pull Request.

**Author**: Daniil Kovekh
